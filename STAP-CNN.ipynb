{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training set: ', (300, 8204), 'Test set: ', (120, 8204))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.io\n",
    "mat1 = scipy.io.loadmat('data/d0417-1.mat')\n",
    "mat2 = scipy.io.loadmat('data/d0417-2.mat')\n",
    "mat3 = scipy.io.loadmat('data/d0417-3.mat')\n",
    "mat4 = scipy.io.loadmat('data/d0417-4.mat')\n",
    "mat5 = scipy.io.loadmat('data/d0417-5.mat')\n",
    "mat6 = scipy.io.loadmat('data/d0417-6.mat')\n",
    "mat7 = scipy.io.loadmat('data/d0417-7.mat')\n",
    "mat8 = scipy.io.loadmat('data/d0417n.mat')\n",
    "\n",
    "TR=np.concatenate([mat8['d1'], mat8['d2'], mat8['d3'], mat8['d7'], mat8['d8']])\n",
    "TS=np.concatenate([mat8['d4'], mat8['d5']])\n",
    "\n",
    "TS6 = mat8['d6']\n",
    "TS7 = mat8['d7']\n",
    "TS8 = mat8['d8']\n",
    "TS9 = mat8['d9']\n",
    "print(\"Training set: \", TR.shape, \"Test set: \", TS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sam_idx = np.linspace(0,8191, 2048, dtype='int8')\n",
    "TR_sam=TR[:,sam_idx]\n",
    "TS_sam=TS[:,sam_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### DEFINE NETWROK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "device_type = \"/cpu:0\"\n",
    "with tf.device(device_type):\n",
    "    n_input=8192\n",
    "    n_output = 12\n",
    "\n",
    "\n",
    "    weights = {\n",
    "        'wc1' : tf.get_variable(\"wc_1\", shape=[2, 7, 1, 1], initializer=tf.contrib.layers.xavier_initializer()),\n",
    "        'wc2' : tf.get_variable(\"wc_2\", shape=[2, 7, 1, 3], initializer=tf.contrib.layers.xavier_initializer()),\n",
    "        'wc3' : tf.get_variable(\"wc_3\", shape=[2, 7, 3, 3], initializer=tf.contrib.layers.xavier_initializer()),\n",
    "        'wd1' : tf.get_variable(\"wc_4\", shape=[(int)(4096/16)*1, 32], initializer=tf.contrib.layers.xavier_initializer()),\n",
    "        'wd2' : tf.get_variable(\"wd_2\", shape=[32, n_output], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    }\n",
    "\n",
    "    biases = {\n",
    "        'bc1' : tf.Variable(tf.random_normal([1], stddev=0.1)),\n",
    "        'bc2' : tf.Variable(tf.random_normal([14], stddev=0.1)),\n",
    "        'bc3' : tf.Variable(tf.random_normal([21], stddev=0.1)),\n",
    "        'bd1' : tf.Variable(tf.random_normal([32], stddev=0.1)),\n",
    "        'bd2' : tf.Variable(tf.random_normal([n_output], stddev=0.1))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "device_type = \"/cpu:0\"\n",
    "with tf.device(device_type):\n",
    "    def conv_stap(_input, _w, _b, _keepratio):\n",
    "        _input_r = tf.reshape(_input, shape=[-1, 2, 4096, 1])\n",
    "        _pool0 = tf.nn.avg_pool(_input_r, ksize=[1,1,4,1], strides=[1,1,4,1], padding='SAME')\n",
    "        _padded = tf.pad(_pool0, [[0,0],[0,0],[3,3],[0,0]], \"CONSTANT\")\n",
    "        _conv1 = tf.nn.conv2d(_padded, _w['wc1'],strides=[1,1,1,1], padding='VALID')\n",
    "        \n",
    "        _mean, _var = tf.nn.moments(_conv1, [0,1,2])\n",
    "        _conv1_n = tf.nn.batch_normalization(_conv1, _mean, _var, 0, 1, 0.0001)\n",
    "        \n",
    "        _conv1_r = tf.nn.relu(_conv1)\n",
    "        _pool1 = tf.nn.max_pool(_conv1_r, ksize=[1,1,4,1], strides=[1,1,4,1], padding='SAME')\n",
    "        _dr1   = tf.nn.dropout(_pool1, _keepratio)\n",
    "\n",
    "        _dense = tf.reshape(_dr1, [-1, _w['wd1'].get_shape().as_list()[0]])\n",
    "\n",
    "        _fc1 = tf.add(tf.matmul(_dense, _w['wd1']), _b['bd1'])\n",
    "        _fc1_relu = tf.nn.relu(_fc1)\n",
    "        _fc_dr1 = tf.nn.dropout(_fc1_relu, _keepratio)\n",
    "\n",
    "        _out = tf.nn.softmax(tf.add(tf.matmul(_fc_dr1, _w['wd2']), _b['bd2']))\n",
    "\n",
    "        out = {\n",
    "            'input_r': _input_r, 'conv1': _conv1, 'pool0': _pool0, 'pool1': _pool1\n",
    "            ,'conv1_n':_conv1_n, 'conv1_r':_conv1_r, 'dense': _dense\n",
    "            , 'dr1': _dr1, 'fc1': _fc1, 'fc1_relu':_fc1_relu, 'fc_dr1': _fc_dr1, 'out': _out\n",
    "            , 'mean': _mean, 'var': _var\n",
    "        }\n",
    "        return out\n",
    "    \n",
    "def lrelu(x, alpha=0.1, max_value=None):\n",
    "    negative_part=tf.nn.relu(-x)\n",
    "    x=tf.nn.relu(x)\n",
    "    \n",
    "    if max_value is not None:\n",
    "        x=tf.clip_by_value(x, tf.cast(0., dtype='float'), tf.cast(max_value, dtype='float'))\n",
    "    \n",
    "    x -= tf.constant(alpha, dtype='float') * negative_part\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# DEFINE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with tf.device(device_type):\n",
    "    x = tf.placeholder(tf.float32, [None, n_input])\n",
    "    y = tf.placeholder(tf.float32, [None, n_output])\n",
    "    keepratio = tf.placeholder(tf.float32)\n",
    "\n",
    "    pred = conv_stap(x, weights, biases, keepratio)['out']\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "    WEIGHT_DECAY_FACTOR = 0.0001\n",
    "    l2_loss = tf.add_n([tf.nn.l2_loss(v)\n",
    "                       for v in tf.trainable_variables()])\n",
    "    cost = cost + WEIGHT_DECAY_FACTOR*l2_loss\n",
    "    optm = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(cost)\n",
    "    corr = tf.equal(tf.argmax(pred,1), tf.argmax(y,1)) # count corrects\n",
    "    accr = tf.reduce_mean(tf.cast(corr, tf.float32))\n",
    "    init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.device(device_type):\n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "    sess.run(init)\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   8,  104,    3,   68,    1,  103,   72,   46,   51,   31,   73,\n",
       "         28,   48,   34,   90,   58,   16,   20,   87,   38,  113,  209,\n",
       "        108,  173,  106,  208,  177,  151,  156,  136,  178,  133,  153,\n",
       "        139,  195,  163,  121,  125,  192,  143,  218,  314,  213,  278,\n",
       "        211,  313,  282,  256,  261,  241,  283,  238,  258,  244,  300,\n",
       "        268,  226,  230,  297,  248,  323,  419,  318,  383,  316,  418,\n",
       "        387,  361,  366,  346,  388,  343,  363,  349,  405,  373,  331,\n",
       "        335,  402,  353,  428,  524,  423,  488,  421,  523,  492,  466,\n",
       "        471,  451,  493,  448,  468,  454,  510,  478,  436,  440,  507,\n",
       "        458,  533,  629,  528,  593,  526,  628,  597,  571,  576,  556,\n",
       "        598,  553,  573,  559,  615,  583,  541,  545,  612,  563,  638,\n",
       "        734,  633,  698,  631,  733,  702,  676,  681,  661,  703,  658,\n",
       "        678,  664,  720,  688,  646,  650,  717,  668,  743,  839,  738,\n",
       "        803,  736,  838,  807,  781,  786,  766,  808,  763,  783,  769,\n",
       "        825,  793,  751,  755,  822,  773,  848,  944,  843,  908,  841,\n",
       "        943,  912,  886,  891,  871,  913,  868,  888,  874,  930,  898,\n",
       "        856,  860,  927,  878,  953, 1049,  948, 1013,  946, 1048, 1017,\n",
       "        991,  996,  976, 1018,  973,  993,  979, 1035, 1003,  961,  965,\n",
       "       1032,  983, 1058, 1154, 1053, 1118, 1051, 1153, 1122, 1096, 1101,\n",
       "       1081, 1123, 1078, 1098, 1084, 1140, 1108, 1066, 1070, 1137, 1088,\n",
       "       1163, 1259, 1158, 1223, 1156, 1258, 1227, 1201, 1206, 1186, 1228,\n",
       "       1183, 1203, 1189, 1245, 1213, 1171, 1175, 1242, 1193])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = 105\n",
    "idx1 = np.random.choice(105, size=20, replace=False)\n",
    "idx2 = idx1+step\n",
    "idx3 = idx1+step*2\n",
    "idx4 = idx1+step*3\n",
    "idx5 = idx1+step*4\n",
    "idx6 = idx1+step*5\n",
    "idx7 = idx1+step*6\n",
    "idx8 = idx1+step*7\n",
    "idx9 = idx1+step*8\n",
    "idx10 = idx1+step*9\n",
    "idx11 = idx1+step*10\n",
    "idx12 = idx1+step*11\n",
    "idx = np.concatenate([idx1,idx2,idx3,idx4,idx5,idx6,idx7,idx8,idx9,idx10,idx11,idx12])\n",
    "idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000/1000 cost: 1.7122\n",
      "TR acc : 0.993, TS acc : 0.825\n",
      "Epoch: 100/1000 cost: 1.7053\n",
      "TR acc : 0.993, TS acc : 0.833\n",
      "Epoch: 200/1000 cost: 1.7019\n",
      "TR acc : 0.993, TS acc : 0.825\n",
      "Epoch: 300/1000 cost: 1.6971\n",
      "TR acc : 0.993, TS acc : 0.842\n",
      "Epoch: 400/1000 cost: 1.6938\n",
      "TR acc : 0.993, TS acc : 0.833\n",
      "Epoch: 500/1000 cost: 1.6922\n",
      "TR acc : 0.993, TS acc : 0.850\n",
      "Epoch: 600/1000 cost: 1.6924\n",
      "TR acc : 0.993, TS acc : 0.842\n",
      "Epoch: 700/1000 cost: 1.6905\n",
      "TR acc : 0.993, TS acc : 0.850\n",
      "Epoch: 800/1000 cost: 1.6896\n",
      "TR acc : 0.993, TS acc : 0.833\n",
      "Epoch: 900/1000 cost: 1.6883\n",
      "TR acc : 0.993, TS acc : 0.850\n",
      "Epoch: 999/1000 cost: 1.6882\n",
      "TR acc : 0.993, TS acc : 0.850\n"
     ]
    }
   ],
   "source": [
    "with tf.device(device_type):\n",
    "    training_epoch = 1000\n",
    "    display_step = 100\n",
    "    batch_size = 180\n",
    "       \n",
    "    for epoch in range(training_epoch):\n",
    "        avg_cost = 0.\n",
    "        num_batch = int(180/batch_size)\n",
    "        for i in range(num_batch):\n",
    "            randidx = np.random.randint(180, size=batch_size)\n",
    "            \n",
    "            batch_xs = TR[:,0:8192]\n",
    "            batch_ys = TR[:,8192:8204]\n",
    "\n",
    "            #training\n",
    "            sess.run(optm, feed_dict={x: batch_xs, y: batch_ys, keepratio: 0.5})\n",
    "            #Compute average loss\n",
    "            avg_cost += sess.run(cost, feed_dict={x: batch_xs, y: batch_ys, keepratio:1.})\n",
    "\n",
    "        if epoch % display_step == 0 or epoch == training_epoch-1:\n",
    "\n",
    "            print(\"Epoch: %03d/%03d cost: %.4f\" % (epoch, training_epoch, avg_cost))\n",
    "            training_acc = sess.run(accr, feed_dict={x: TR[:,0:8192], y: TR[:,8192:8204], keepratio:1.})\n",
    "            test_acc     = sess.run(accr, feed_dict={x: TS[:,0:8192], y: TS[:,8192:8204], keepratio:1.})\n",
    "            #acc = (training_acc*50 + test_acc*20 )/70\n",
    "            print(\"TR acc : %.3f, TS acc : %.3f\" % (training_acc, test_acc))\n",
    "            #print(\"Test acc : %.3f\" %(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# STORE PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_path = saver.save(sess, \"parameters/model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# RESTORE PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "saver.restore(sess, \"parameters/model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ACC CLASS BY CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 01 : 1.000 \n",
      "acc 02 : 1.000 \n",
      "acc 03 : 0.700 \n",
      "acc 04 : 1.000 \n",
      "acc 05 : 0.900 \n",
      "acc 06 : 0.900 \n",
      "acc 07 : 1.000 \n",
      "acc 08 : 0.500 \n",
      "acc 09 : 0.700 \n",
      "acc 10 : 1.000 \n",
      "acc 11 : 1.000 \n",
      "acc 12 : 1.000 \n"
     ]
    }
   ],
   "source": [
    "DS = np.concatenate([TS])\n",
    "max_index = np.ndarray.argmax(DS[:,8192:],axis=1)\n",
    "c01_index = np.where(max_index==0)\n",
    "c02_index = np.where(max_index==1)\n",
    "c03_index = np.where(max_index==2)\n",
    "c04_index = np.where(max_index==3)\n",
    "c05_index = np.where(max_index==4)\n",
    "c06_index = np.where(max_index==5)\n",
    "c07_index = np.where(max_index==6)\n",
    "c08_index = np.where(max_index==7)\n",
    "c09_index = np.where(max_index==8)\n",
    "c10_index = np.where(max_index==9)\n",
    "c11_index = np.where(max_index==10)\n",
    "c12_index = np.where(max_index==11)\n",
    "acc01 = sess.run(accr, feed_dict={x:DS[c01_index,0:8192][0,:,:], y:DS[c01_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc02 = sess.run(accr, feed_dict={x:DS[c02_index,0:8192][0,:,:], y:DS[c02_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc03 = sess.run(accr, feed_dict={x:DS[c03_index,0:8192][0,:,:], y:DS[c03_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc04 = sess.run(accr, feed_dict={x:DS[c04_index,0:8192][0,:,:], y:DS[c04_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc05 = sess.run(accr, feed_dict={x:DS[c05_index,0:8192][0,:,:], y:DS[c05_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc06 = sess.run(accr, feed_dict={x:DS[c06_index,0:8192][0,:,:], y:DS[c06_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc07 = sess.run(accr, feed_dict={x:DS[c07_index,0:8192][0,:,:], y:DS[c07_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc08 = sess.run(accr, feed_dict={x:DS[c08_index,0:8192][0,:,:], y:DS[c08_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc09 = sess.run(accr, feed_dict={x:DS[c09_index,0:8192][0,:,:], y:DS[c09_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc10 = sess.run(accr, feed_dict={x:DS[c10_index,0:8192][0,:,:], y:DS[c10_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc11 = sess.run(accr, feed_dict={x:DS[c11_index,0:8192][0,:,:], y:DS[c11_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc12 = sess.run(accr, feed_dict={x:DS[c12_index,0:8192][0,:,:], y:DS[c12_index,8192:8204][0,:,:], keepratio:1.})\n",
    "print(\"acc 01 : %.3f \\nacc 02 : %.3f \\nacc 03 : %.3f \\nacc 04 : %.3f \\nacc 05 : %.3f \\nacc 06 : %.3f \\nacc 07 : %.3f \\nacc 08 : %.3f \\nacc 09 : %.3f \\nacc 10 : %.3f \\nacc 11 : %.3f \\nacc 12 : %.3f \" \n",
    "      %(acc01, acc02, acc03, acc04, acc05, acc06, acc07, acc08, acc09, acc10, acc11, acc12))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# SAVE PARAMETERS FOR ANDROID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 7, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "wc = sess.run(weights['wc1'])\n",
    "wf1 = sess.run(weights['wd1'])\n",
    "wf2 = sess.run(weights['wd2'])\n",
    "bf1 = sess.run(biases['bd1'])\n",
    "bf2 = sess.run(biases['bd2'])\n",
    "Weights = {\n",
    "    'wc':wc,\n",
    "    'wf1':wf1,\n",
    "    'wf2':wf2,\n",
    "    'bf1':bf1,\n",
    "    'bf2':bf2,\n",
    "}\n",
    "smat2 = scipy.io.savemat('data/savemat1.mat', Weights)\n",
    "\n",
    "print(wc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "f = open(\"data/save1.txt\", 'weights')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.983333\n",
      "('1: ', array([1, 6, 1, 1, 1]))\n",
      "('2: ', array([2, 2, 2, 2, 2]))\n",
      "('3: ', array([3, 3, 3, 3, 3]))\n",
      "('4: ', array([4, 4, 4, 4, 4]))\n",
      "('5: ', array([5, 5, 5, 5, 5]))\n",
      "('6: ', array([6, 6, 6, 6, 6]))\n",
      "('7: ', array([7, 7, 7, 7, 7]))\n",
      "('8: ', array([8, 8, 8, 8, 8]))\n",
      "('9: ', array([9, 9, 9, 9, 9]))\n",
      "('10: ', array([10, 10, 10, 10, 10]))\n",
      "('11: ', array([11, 11, 11, 11, 11]))\n",
      "('12: ', array([12, 12, 12, 12, 12]))\n"
     ]
    }
   ],
   "source": [
    "TSset = TS6\n",
    "t1 = sess.run(pred, feed_dict={x:TSset[:,:8192], keepratio:1.} )\n",
    "max_index = np.ndarray.argmax(t1,axis=1)\n",
    "\n",
    "ntest_acc=sess.run(accr, feed_dict={x:TSset[:,0:8192], y:TSset[:,8192:8204], keepratio:1.})\n",
    "print(ntest_acc)\n",
    "\n",
    "print(\"1: \", max_index[0:5] +1)\n",
    "print(\"2: \", max_index[5:10] +1)\n",
    "print(\"3: \", max_index[10:15] +1)\n",
    "print(\"4: \", max_index[15:20] +1)\n",
    "print(\"5: \", max_index[20:25] +1)\n",
    "print(\"6: \", max_index[25:30] +1)\n",
    "print(\"7: \", max_index[30:35] +1)\n",
    "print(\"8: \", max_index[35:40] +1)\n",
    "print(\"9: \", max_index[40:45] +1)\n",
    "print(\"10: \", max_index[45:50] +1)\n",
    "print(\"11: \", max_index[50:55] +1)\n",
    "print(\"12: \", max_index[55:60] +1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
