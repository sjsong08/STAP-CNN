{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1260, 8204)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.io\n",
    "mat1 = scipy.io.loadmat('data/d0404.mat')\n",
    "TR=mat1['normd0404']\n",
    "#TS=mat1['N_normNTS']\n",
    "TR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sam_idx = np.linspace(0,8191, 2048, dtype='int8')\n",
    "TR_sam=TR[:,sam_idx]\n",
    "#TS_sam=TS[:,sam_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### DEFINE NETWROK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "device_type = \"/cpu:0\"\n",
    "with tf.device(device_type):\n",
    "    n_input=8192\n",
    "    n_output = 12\n",
    "\n",
    "\n",
    "    weights = {\n",
    "        'wc1' : tf.get_variable(\"wc_1\", shape=[2, 7, 1, 1], initializer=tf.contrib.layers.xavier_initializer()),\n",
    "        'wc2' : tf.get_variable(\"wc_2\", shape=[2, 7, 1, 3], initializer=tf.contrib.layers.xavier_initializer()),\n",
    "        'wc3' : tf.get_variable(\"wc_3\", shape=[2, 7, 3, 3], initializer=tf.contrib.layers.xavier_initializer()),\n",
    "        'wd1' : tf.get_variable(\"wc_4\", shape=[(int)(4096/16)*1, 32], initializer=tf.contrib.layers.xavier_initializer()),\n",
    "        'wd2' : tf.get_variable(\"wd_2\", shape=[32, n_output], initializer=tf.contrib.layers.xavier_initializer())\n",
    "    }\n",
    "\n",
    "    biases = {\n",
    "        'bc1' : tf.Variable(tf.random_normal([1], stddev=0.1)),\n",
    "        'bc2' : tf.Variable(tf.random_normal([14], stddev=0.1)),\n",
    "        'bc3' : tf.Variable(tf.random_normal([21], stddev=0.1)),\n",
    "        'bd1' : tf.Variable(tf.random_normal([32], stddev=0.1)),\n",
    "        'bd2' : tf.Variable(tf.random_normal([n_output], stddev=0.1))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n_conv2 = tf.nn.conv2d(_dr1, _w['wc2'],strides=[1,1,1,1], padding='SAME')\\n_mean, _var = tf.nn.moments(_conv2, [0,1,2])\\n_conv2 = tf.nn.batch_normalization(_conv2, _mean, _var, 0, 1, 0.0001)\\n_conv2 = tf.nn.relu(_conv2)\\n_pool2 = tf.nn.max_pool(_conv2, ksize=[1,1,4,1], strides=[1,1,4,1], padding='SAME')\\n_dr2   = tf.nn.dropout(_pool2, _keepratio)\\n\\n_conv3 = tf.nn.conv2d(_dr2, _w['wc3'],strides=[1,1,1,1], padding='SAME')\\n_mean, _var = tf.nn.moments(_conv3, [0,1,2])\\n_conv3 = tf.nn.batch_normalization(_conv3, _mean, _var, 0, 1, 0.0001)\\n_conv3 = tf.nn.relu(_conv3)\\n_pool3 = tf.nn.max_pool(_conv3, ksize=[1,1,4,1], strides=[1,1,4,1], padding='SAME')\\n_dr3   = tf.nn.dropout(_pool3, _keepratio)\\n\\n'conv2': _conv2, 'pool2': _pool2, 'dense': _dense\\n, 'dr2': _dr2, 'conv3': _conv3, 'pool3': _pool3\\n, 'dr3': _dr3, \\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_type = \"/cpu:0\"\n",
    "with tf.device(device_type):\n",
    "    def conv_stap(_input, _w, _b, _keepratio):\n",
    "        _input_r = tf.reshape(_input, shape=[-1, 2, 4096, 1])\n",
    "        _pool0 = tf.nn.avg_pool(_input_r, ksize=[1,1,4,1], strides=[1,1,4,1], padding='SAME')\n",
    "        _padded = tf.pad(_pool0, [[0,0],[0,0],[3,3],[0,0]], \"CONSTANT\")\n",
    "        _conv1 = tf.nn.conv2d(_padded, _w['wc1'],strides=[1,1,1,1], padding='VALID')\n",
    "        \n",
    "        _mean, _var = tf.nn.moments(_conv1, [0,1,2])\n",
    "        _conv1_n = tf.nn.batch_normalization(_conv1, _mean, _var, 0, 1, 0.0001)\n",
    "        \n",
    "        _conv1_r = tf.nn.sigmoid(_conv1)\n",
    "        _pool1 = tf.nn.max_pool(_conv1_r, ksize=[1,1,4,1], strides=[1,1,4,1], padding='SAME')\n",
    "        _dr1   = tf.nn.dropout(_pool1, _keepratio)\n",
    "\n",
    "        _dense = tf.reshape(_dr1, [-1, _w['wd1'].get_shape().as_list()[0]])\n",
    "\n",
    "        _fc1 = tf.add(tf.matmul(_dense, _w['wd1']), _b['bd1'])\n",
    "        _fc1_relu = tf.nn.sigmoid(_fc1)\n",
    "        _fc_dr1 = tf.nn.dropout(_fc1_relu, _keepratio)\n",
    "\n",
    "        _out = tf.add(tf.matmul(_fc_dr1, _w['wd2']), _b['bd2'])\n",
    "\n",
    "        out = {\n",
    "            'input_r': _input_r, 'conv1': _conv1, 'pool0': _pool0, 'pool1': _pool1\n",
    "            ,'conv1_n':_conv1_n, 'conv1_r':_conv1_r, 'dense': _dense\n",
    "            , 'dr1': _dr1, 'fc1': _fc1, 'fc1_relu':_fc1_relu, 'fc_dr1': _fc_dr1, 'out': _out\n",
    "            , 'mean': _mean, 'var': _var\n",
    "        }\n",
    "        return out\n",
    "    \n",
    "def lrelu(x, alpha=0.1, max_value=None):\n",
    "    negative_part=tf.nn.relu(-x)\n",
    "    x=tf.nn.relu(x)\n",
    "    \n",
    "    if max_value is not None:\n",
    "        x=tf.clip_by_value(x, tf.cast(0., dtype='float'), tf.cast(max_value, dtype='float'))\n",
    "    \n",
    "    x -= tf.constant(alpha, dtype='float') * negative_part\n",
    "    return x\n",
    "\n",
    "\n",
    "'''\n",
    "_conv2 = tf.nn.conv2d(_dr1, _w['wc2'],strides=[1,1,1,1], padding='SAME')\n",
    "_mean, _var = tf.nn.moments(_conv2, [0,1,2])\n",
    "_conv2 = tf.nn.batch_normalization(_conv2, _mean, _var, 0, 1, 0.0001)\n",
    "_conv2 = tf.nn.relu(_conv2)\n",
    "_pool2 = tf.nn.max_pool(_conv2, ksize=[1,1,4,1], strides=[1,1,4,1], padding='SAME')\n",
    "_dr2   = tf.nn.dropout(_pool2, _keepratio)\n",
    "\n",
    "_conv3 = tf.nn.conv2d(_dr2, _w['wc3'],strides=[1,1,1,1], padding='SAME')\n",
    "_mean, _var = tf.nn.moments(_conv3, [0,1,2])\n",
    "_conv3 = tf.nn.batch_normalization(_conv3, _mean, _var, 0, 1, 0.0001)\n",
    "_conv3 = tf.nn.relu(_conv3)\n",
    "_pool3 = tf.nn.max_pool(_conv3, ksize=[1,1,4,1], strides=[1,1,4,1], padding='SAME')\n",
    "_dr3   = tf.nn.dropout(_pool3, _keepratio)\n",
    "\n",
    "'conv2': _conv2, 'pool2': _pool2, 'dense': _dense\n",
    ", 'dr2': _dr2, 'conv3': _conv3, 'pool3': _pool3\n",
    ", 'dr3': _dr3, \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# DEFINE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with tf.device(device_type):\n",
    "    x = tf.placeholder(tf.float32, [None, n_input])\n",
    "    y = tf.placeholder(tf.float32, [None, n_output])\n",
    "    keepratio = tf.placeholder(tf.float32)\n",
    "\n",
    "    pred = conv_stap(x, weights, biases, keepratio)['out']\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "    WEIGHT_DECAY_FACTOR = 0.0001\n",
    "    l2_loss = tf.add_n([tf.nn.l2_loss(v)\n",
    "                       for v in tf.trainable_variables()])\n",
    "    cost = cost + WEIGHT_DECAY_FACTOR*l2_loss\n",
    "    optm = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(cost)\n",
    "    corr = tf.equal(tf.argmax(pred,1), tf.argmax(y,1)) # count corrects\n",
    "    accr = tf.reduce_mean(tf.cast(corr, tf.float32))\n",
    "    init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.device(device_type):\n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "    sess.run(init)\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  45,   67,   18,   66,   12,   81,    4,   65,   27,   96,   70,\n",
       "          2,   86,   13,   39,   16,   29,   10,   32,   73,  150,  172,\n",
       "        123,  171,  117,  186,  109,  170,  132,  201,  175,  107,  191,\n",
       "        118,  144,  121,  134,  115,  137,  178,  255,  277,  228,  276,\n",
       "        222,  291,  214,  275,  237,  306,  280,  212,  296,  223,  249,\n",
       "        226,  239,  220,  242,  283,  360,  382,  333,  381,  327,  396,\n",
       "        319,  380,  342,  411,  385,  317,  401,  328,  354,  331,  344,\n",
       "        325,  347,  388,  465,  487,  438,  486,  432,  501,  424,  485,\n",
       "        447,  516,  490,  422,  506,  433,  459,  436,  449,  430,  452,\n",
       "        493,  570,  592,  543,  591,  537,  606,  529,  590,  552,  621,\n",
       "        595,  527,  611,  538,  564,  541,  554,  535,  557,  598,  675,\n",
       "        697,  648,  696,  642,  711,  634,  695,  657,  726,  700,  632,\n",
       "        716,  643,  669,  646,  659,  640,  662,  703,  780,  802,  753,\n",
       "        801,  747,  816,  739,  800,  762,  831,  805,  737,  821,  748,\n",
       "        774,  751,  764,  745,  767,  808,  885,  907,  858,  906,  852,\n",
       "        921,  844,  905,  867,  936,  910,  842,  926,  853,  879,  856,\n",
       "        869,  850,  872,  913,  990, 1012,  963, 1011,  957, 1026,  949,\n",
       "       1010,  972, 1041, 1015,  947, 1031,  958,  984,  961,  974,  955,\n",
       "        977, 1018, 1095, 1117, 1068, 1116, 1062, 1131, 1054, 1115, 1077,\n",
       "       1146, 1120, 1052, 1136, 1063, 1089, 1066, 1079, 1060, 1082, 1123,\n",
       "       1200, 1222, 1173, 1221, 1167, 1236, 1159, 1220, 1182, 1251, 1225,\n",
       "       1157, 1241, 1168, 1194, 1171, 1184, 1165, 1187, 1228])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step = 105\n",
    "idx1 = np.random.choice(105, size=20, replace=False)\n",
    "idx2 = idx1+step\n",
    "idx3 = idx1+step*2\n",
    "idx4 = idx1+step*3\n",
    "idx5 = idx1+step*4\n",
    "idx6 = idx1+step*5\n",
    "idx7 = idx1+step*6\n",
    "idx8 = idx1+step*7\n",
    "idx9 = idx1+step*8\n",
    "idx10 = idx1+step*9\n",
    "idx11 = idx1+step*10\n",
    "idx12 = idx1+step*11\n",
    "idx = np.concatenate([idx1,idx2,idx3,idx4,idx5,idx6,idx7,idx8,idx9,idx10,idx11,idx12])\n",
    "idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000/1000 cost: 2.7005\n",
      "TR acc : 0.083, TS acc : 0.083\n",
      "Epoch: 100/1000 cost: 2.4865\n",
      "TR acc : 0.083, TS acc : 0.083\n",
      "Epoch: 200/1000 cost: 2.4880\n",
      "TR acc : 0.083, TS acc : 0.083\n",
      "Epoch: 300/1000 cost: 2.4876\n",
      "TR acc : 0.083, TS acc : 0.083\n",
      "Epoch: 400/1000 cost: 2.4853\n",
      "TR acc : 0.125, TS acc : 0.117\n",
      "Epoch: 500/1000 cost: 2.4600\n",
      "TR acc : 0.296, TS acc : 0.290\n"
     ]
    }
   ],
   "source": [
    "with tf.device(device_type):\n",
    "    training_epoch = 1000\n",
    "    display_step = 100\n",
    "    batch_size = 1260\n",
    "       \n",
    "    for epoch in range(training_epoch):\n",
    "        avg_cost = 0.\n",
    "        num_batch = int(1260/batch_size)\n",
    "        for i in range(num_batch):\n",
    "            randidx = np.random.randint(1260, size=batch_size)\n",
    "            \n",
    "            batch_xs = TR[randidx,0:8192]\n",
    "            batch_ys = TR[randidx,8192:8204]\n",
    "\n",
    "            #training\n",
    "            sess.run(optm, feed_dict={x: batch_xs, y: batch_ys, keepratio: 0.5})\n",
    "            #Compute average loss\n",
    "            avg_cost += sess.run(cost, feed_dict={x: batch_xs, y: batch_ys, keepratio:1.})\n",
    "\n",
    "        if epoch % display_step == 0 or epoch == training_epoch-1:\n",
    "\n",
    "            print(\"Epoch: %03d/%03d cost: %.4f\" % (epoch, training_epoch, avg_cost))\n",
    "            training_acc = sess.run(accr, feed_dict={x: TR[idx,0:8192], y: TR[idx,8192:8204], keepratio:1.})\n",
    "            test_acc     = sess.run(accr, feed_dict={x: TR[:,0:8192], y: TR[:,8192:8204], keepratio:1.})\n",
    "            #acc = (training_acc*50 + test_acc*20 )/70\n",
    "            print(\"TR acc : %.3f, TS acc : %.3f\" % (training_acc, test_acc))\n",
    "            #print(\"Test acc : %.3f\" %(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# STORE PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "save_path = saver.save(sess, \"parameters/model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# RESTORE PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "saver.restore(sess, \"parameters/model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# ACC CLASS BY CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 01 : 1.000 \n",
      "acc 02 : 0.705 \n",
      "acc 03 : 0.962 \n",
      "acc 04 : 1.000 \n",
      "acc 05 : 1.000 \n",
      "acc 06 : 1.000 \n",
      "acc 07 : 1.000 \n",
      "acc 08 : 1.000 \n",
      "acc 09 : 1.000 \n",
      "acc 10 : 1.000 \n",
      "acc 11 : 1.000 \n",
      "acc 12 : 0.971 \n"
     ]
    }
   ],
   "source": [
    "DS = np.concatenate([TR])\n",
    "max_index = np.ndarray.argmax(DS[:,8192:],axis=1)\n",
    "c01_index = np.where(max_index==0)\n",
    "c02_index = np.where(max_index==1)\n",
    "c03_index = np.where(max_index==2)\n",
    "c04_index = np.where(max_index==3)\n",
    "c05_index = np.where(max_index==4)\n",
    "c06_index = np.where(max_index==5)\n",
    "c07_index = np.where(max_index==6)\n",
    "c08_index = np.where(max_index==7)\n",
    "c09_index = np.where(max_index==8)\n",
    "c10_index = np.where(max_index==9)\n",
    "c11_index = np.where(max_index==10)\n",
    "c12_index = np.where(max_index==11)\n",
    "acc01 = sess.run(accr, feed_dict={x:DS[c01_index,0:8192][0,:,:], y:DS[c01_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc02 = sess.run(accr, feed_dict={x:DS[c02_index,0:8192][0,:,:], y:DS[c02_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc03 = sess.run(accr, feed_dict={x:DS[c03_index,0:8192][0,:,:], y:DS[c03_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc04 = sess.run(accr, feed_dict={x:DS[c04_index,0:8192][0,:,:], y:DS[c04_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc05 = sess.run(accr, feed_dict={x:DS[c05_index,0:8192][0,:,:], y:DS[c05_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc06 = sess.run(accr, feed_dict={x:DS[c06_index,0:8192][0,:,:], y:DS[c06_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc07 = sess.run(accr, feed_dict={x:DS[c07_index,0:8192][0,:,:], y:DS[c07_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc08 = sess.run(accr, feed_dict={x:DS[c08_index,0:8192][0,:,:], y:DS[c08_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc09 = sess.run(accr, feed_dict={x:DS[c09_index,0:8192][0,:,:], y:DS[c09_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc10 = sess.run(accr, feed_dict={x:DS[c10_index,0:8192][0,:,:], y:DS[c10_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc11 = sess.run(accr, feed_dict={x:DS[c11_index,0:8192][0,:,:], y:DS[c11_index,8192:8204][0,:,:], keepratio:1.})\n",
    "acc12 = sess.run(accr, feed_dict={x:DS[c12_index,0:8192][0,:,:], y:DS[c12_index,8192:8204][0,:,:], keepratio:1.})\n",
    "print(\"acc 01 : %.3f \\nacc 02 : %.3f \\nacc 03 : %.3f \\nacc 04 : %.3f \\nacc 05 : %.3f \\nacc 06 : %.3f \\nacc 07 : %.3f \\nacc 08 : %.3f \\nacc 09 : %.3f \\nacc 10 : %.3f \\nacc 11 : %.3f \\nacc 12 : %.3f \" \n",
    "      %(acc01, acc02, acc03, acc04, acc05, acc06, acc07, acc08, acc09, acc10, acc11, acc12))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# SAVE PARAMETERS FOR ANDROID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 1.1414156 ]]\n",
      "\n",
      "  [[ 1.02894175]]\n",
      "\n",
      "  [[ 1.22700822]]\n",
      "\n",
      "  [[ 0.84509301]]\n",
      "\n",
      "  [[-0.8457315 ]]\n",
      "\n",
      "  [[-1.30150235]]\n",
      "\n",
      "  [[-1.32011771]]]\n",
      "\n",
      "\n",
      " [[[-1.09077644]]\n",
      "\n",
      "  [[-1.39412284]]\n",
      "\n",
      "  [[-1.35836887]]\n",
      "\n",
      "  [[-1.21993411]]\n",
      "\n",
      "  [[-0.81074131]]\n",
      "\n",
      "  [[-0.84921652]]\n",
      "\n",
      "  [[ 1.03848755]]]]\n",
      "(2, 7, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "wc = sess.run(weights['wc1'])\n",
    "wf1 = sess.run(weights['wd1'])\n",
    "wf2 = sess.run(weights['wd2'])\n",
    "bf1 = sess.run(biases['bd1'])\n",
    "bf2 = sess.run(biases['bd2'])\n",
    "Weights = {\n",
    "    'wc':wc,\n",
    "    'wf1':wf1,\n",
    "    'wf2':wf2,\n",
    "    'bf1':bf1,\n",
    "    'bf2':bf2,\n",
    "}\n",
    "smat2 = scipy.io.savemat('data/savemat1.mat', Weights)\n",
    "print(wc)\n",
    "print(wc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "f = open(\"data/save1.txt\", 'weights')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0037235990721523624"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat2 = scipy.io.loadmat('data/d0407.mat')\n",
    "TRset = mat2['normd0407']\n",
    "TRset.shape\n",
    "TRset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 3, 3, 4, 6, 5, 5, 5,\n",
       "       1, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = sess.run(pred, feed_dict={x:TRset, keepratio:1.} )\n",
    "max_index = np.ndarray.argmax(t1,axis=1)\n",
    "max_index +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          1.74668443  0.          0.          1.45507741  1.96513557\n",
      "   1.53743565  0.          1.68994725  0.88912308  1.06961167  0.92114025\n",
      "   0.76851153  0.          1.39314497  1.93270028  0.20780337  0.          0.\n",
      "   1.52531314  0.          2.27788544  0.          0.0962585   0.          0.\n",
      "   0.16577657  0.89982635  0.          0.          0.          0.        ]]\n",
      "(1, 32)\n"
     ]
    }
   ],
   "source": [
    "pred1 = conv_stap(x, weights, biases, keepratio)['fc1_relu']\n",
    "\n",
    "aa=sess.run(pred1, feed_dict={x:TRset[:1,:], keepratio:1.})\n",
    "print(aa)\n",
    "print(aa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11.15924263,  -1.19474912,  -5.00782442,  -7.39699841,\n",
       "         -2.99421239,  -3.61619949,  -3.82316136, -12.86284161,\n",
       "         -7.10066319, -10.6728363 ,  -8.37771416,  -1.03177774]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa= tf.matmul(aa, wf2)\n",
    "sess.run(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
